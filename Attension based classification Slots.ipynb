{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravroy/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, pickle, sys, json, random, math \n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# from keras.np_utils import probas_to_classes\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, add, concatenate, TimeDistributed, Bidirectional, merge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.layers import Dense, Input, Flatten, Merge, Dropout, concatenate, Concatenate\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = []\n",
    "with open('/home/gauravroy/Desktop/slotfilling/ATIS_train.iob','r') as f:\n",
    "    for line in f:\n",
    "        raw_train.append(line)\n",
    "        \n",
    "raw_test = []\n",
    "with open('/home/gauravroy/Desktop/slotfilling/ATIS_test.iob','r') as f:\n",
    "    for line in f:\n",
    "        raw_test.append(line)\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/embedding_matrix.pickle', 'rb') as fp:\n",
    "    embedding_matrix = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/embedding_matrix_w.pickle', 'rb') as fp:\n",
    "    embedding_matrix_w = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/embedding_matrix_g.pickle', 'rb') as fp:\n",
    "    embedding_matrix_g = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/embedding_matrix_pos.pickle', 'rb') as fp:\n",
    "     embedding_matrix_pos = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/train_sequence.pickle', 'rb') as fp:\n",
    "    train_sequence = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/test_sequence.pickle', 'rb') as fp:\n",
    "    test_sequence = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/train_sequence1.pickle', 'rb') as fp:\n",
    "    train_sequence1 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/test_sequence1.pickle', 'rb') as fp:\n",
    "    test_sequence1 = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling//slot_word_dict.pickle', 'rb') as fp:\n",
    "    slot_word_dict = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/y_train_slot.pickle', 'rb') as fp:\n",
    "    y_train_slot = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/y_test_slot.pickle', 'rb') as fp:\n",
    "    y_test_slot = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/x_train_pos.pickle', 'rb') as fp:\n",
    "    x_train_pos = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/gauravroy/Desktop/slotfilling/x_test_pos.pickle', 'rb') as fp:\n",
    "    x_test_pos = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "slot_dict, words_dict = slot_word_dict\n",
    "\n",
    "train_sequence = pad_sequences(train_sequence, maxlen = 46, padding='post')\n",
    "test_sequence = pad_sequences(test_sequence, maxlen = 46, padding='post') \n",
    "\n",
    "max_len = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(slot_dict)\n",
    "\n",
    "y_train_slot = list()\n",
    "for utterance in raw_train:\n",
    "    outs = np.zeros((max_len,len(slot_dict)))\n",
    "    outs = list(outs)\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs[i][slot_dict[slots[i]]] = 1\n",
    "    y_train_slot.append(outs)\n",
    "    \n",
    "y_test_slot = list()\n",
    "for utterance in raw_test:\n",
    "    outs = np.zeros((max_len,len(slot_dict)))\n",
    "    outs = list(outs)\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs[i][slot_dict[slots[i]]] = 1\n",
    "    y_test_slot.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(slot_dict)\n",
    "\n",
    "z_train_slot = list()\n",
    "for utterance in raw_train:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs.append(slot_dict[slots[i]])\n",
    "    z_train_slot.append(outs)\n",
    "    \n",
    "z_test_slot = list()\n",
    "for utterance in raw_test:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs.append(slot_dict[slots[i]])\n",
    "    z_test_slot.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(mat):\n",
    "    arr = list()\n",
    "    for ar in mat:\n",
    "        for a in ar:\n",
    "            arr.append(a)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_z_pred_slot(mat,z_act_slot):\n",
    "    ans = list()\n",
    "    for i in range(len(mat)):\n",
    "        ans.append(mat[i][:len(z_act_slot[i])])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(list1, list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        print(\"Size of a the lists not equal\")\n",
    "        return\n",
    "    count = 0.0\n",
    "    for i in range(len(list1)):\n",
    "        if(list1[i] == list2[i]):\n",
    "            count = count + 1\n",
    "            \n",
    "    return count/len(list1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravroy/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/gauravroy/.local/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/gauravroy/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=127)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "lstm_embedding_layer = Embedding(len(embedding_matrix_g), len(embedding_matrix_g[0]), weights=[embedding_matrix_g], input_length=max_len, \n",
    "                            trainable=False, mask_zero = True)\n",
    "\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "\n",
    "lstm_embedded_sequences = lstm_embedding_layer(sequence_input)\n",
    "\n",
    "forward = LSTM(200, return_sequences=True)(lstm_embedded_sequences)\n",
    "backward = LSTM(200, return_sequences=True,go_backwards=True)(lstm_embedded_sequences)\n",
    "\n",
    "tagger = merge([forward, backward], mode='concat')\n",
    "\n",
    "#tagger = Dropout(self.dropout_ratio)(tagger)\n",
    "\n",
    "prediction = TimeDistributed(Dense(output_dim=127, activation='softmax'))(tagger)\n",
    "\n",
    "out = Dense(units=200, activation='relu', kernel_initializer='he_normal')(prediction)\n",
    "out = Dense(units=len(slot_dict), activation='softmax', kernel_initializer='he_normal')(out)\n",
    "\n",
    "graph = Model(inputs=sequence_input, outputs=prediction)\n",
    "graph.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4978 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      " - 34s - loss: 2.9899 - acc: 0.6348 - categorical_accuracy: 0.6348 - val_loss: 2.4942 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59935, saving model to /home/gauravroy/Desktop/slotfilling/hdf5/g_lstm.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravroy/.local/lib/python3.6/site-packages/keras/engine/topology.py:2379: UserWarning: Layer merge_1 was passed non-serializable keyword arguments: {'mask': [<tf.Tensor 'embedding_1/NotEqual:0' shape=(?, 46) dtype=bool>, <tf.Tensor 'embedding_1/NotEqual:0' shape=(?, 46) dtype=bool>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 33s - loss: 2.1198 - acc: 0.6348 - categorical_accuracy: 0.6348 - val_loss: 2.2033 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.59935\n",
      "Epoch 3/10\n",
      " - 35s - loss: 1.9281 - acc: 0.6347 - categorical_accuracy: 0.6347 - val_loss: 2.0718 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.59935\n",
      "Epoch 4/10\n",
      " - 35s - loss: 1.8484 - acc: 0.6345 - categorical_accuracy: 0.6345 - val_loss: 2.0275 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.59935\n",
      "Epoch 5/10\n",
      " - 36s - loss: 1.7934 - acc: 0.6347 - categorical_accuracy: 0.6347 - val_loss: 1.9655 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.59935\n",
      "Epoch 6/10\n",
      " - 36s - loss: 1.7367 - acc: 0.6347 - categorical_accuracy: 0.6347 - val_loss: 1.9137 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.59935\n",
      "Epoch 7/10\n",
      " - 35s - loss: 1.6837 - acc: 0.6346 - categorical_accuracy: 0.6346 - val_loss: 1.8614 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.59935\n",
      "Epoch 8/10\n",
      " - 36s - loss: 1.6446 - acc: 0.6347 - categorical_accuracy: 0.6347 - val_loss: 1.8182 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.59935\n",
      "Epoch 9/10\n",
      " - 36s - loss: 1.6219 - acc: 0.6345 - categorical_accuracy: 0.6345 - val_loss: 1.8003 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.59935\n",
      "Epoch 10/10\n",
      " - 37s - loss: 1.6110 - acc: 0.6344 - categorical_accuracy: 0.6344 - val_loss: 1.7891 - val_acc: 0.5994 - val_categorical_accuracy: 0.5994\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.59935\n"
     ]
    }
   ],
   "source": [
    "saveBestModel = ModelCheckpoint(filepath=\"/home/gauravroy/Desktop/slotfilling/hdf5/g_lstm.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "graph.fit(train_sequence, np.array(y_train_slot),validation_data=(test_sequence,np.array(y_test_slot)), epochs=10, batch_size=50, verbose=2, callbacks=[saveBestModel])\n",
    "#graph.load_weights(\"/home/gauravroy/Desktop/slotfilling/hdf5/g_lstm.hdf5\")\n",
    "\n",
    "lstm_pred_train = graph.predict(train_sequence)\n",
    "lstm_pred_test = graph.predict(test_sequence)\n",
    "\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "lstm_pred_classes_test = lstm_pred_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "z_pred_slot_test = make_z_pred_slot(lstm_pred_classes_test,z_test_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.49284069196626834\n",
      "Test F1: 0.4503458217073495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravroy/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train F1: \" + str(f1_score(flatten(z_train_slot),flatten(z_pred_slot_train), average = 'weighted')))\n",
    "print (\"Test F1: \" + str(f1_score(flatten(z_test_slot),flatten(z_pred_slot_test), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 63.46797153024911%\n",
      "Test Accuracy: 60.028371890004365%\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: \" + str(accu(flatten(z_train_slot),flatten(z_pred_slot_train))*100) + \"%\")\n",
    "print (\"Test Accuracy: \" + str(accu(flatten(z_test_slot),flatten(z_pred_slot_test))*100) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
